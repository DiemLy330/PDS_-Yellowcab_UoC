{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cabana import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sys import getsizeof\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "        # Test geo() module,\n",
    "    # data = geo()\n",
    "    # print(data.get_centroid()) # giving a dict of approx. 260 keys\n",
    "    # print(data.map_locationID(location=10))\n",
    "    # print(data.get_map())\n",
    "    # print(data.df())\n",
    "#-------------------------------------------------------------\n",
    "        #Test trip_inputs() module\n",
    "    # x = trips_input()\n",
    "    # b = x.borough_list()\n",
    "    # l = x.get_borough_locationID(borough=\"Bronx\")\n",
    "    # print(b,l)\n",
    "\n",
    "    # t = x.get_trips(fraction=1)\n",
    "    # print(t.info())\n",
    "    # print(t.head())\n",
    "\n",
    "    #     # Histogram of passenger_count\n",
    "    # counts, bins = np.histogram(t.iloc[:,2], bins=10, range=(0, 10))\n",
    "    # print(counts, bins)\n",
    "    # plt.ylim([0,6000000])\n",
    "    # plt.xlim([0,10])\n",
    "    # plt.hist(bins[:-1], bins, weights=counts, color='mediumblue', ec='darkblue')\n",
    "    # plt.show()\n",
    "#-------------------------------------------------------------\n",
    "       #Test trips_info() module\n",
    "    # y = trips_info(t)\n",
    "    # df = y.get_time(column='tpep_dropoff_datetime')\n",
    "    # print(df.info())\n",
    "    # print(df.head())\n",
    "\n",
    "    # d = y.get_duration()\n",
    "    # print(d.head())\n",
    "    # print(d.info())\n",
    "    #\n",
    "    # df = y.get_position()\n",
    "    # print(df.info())\n",
    "\n",
    "    # a,b,c = y.outlier(df['longitude'])\n",
    "    # d,e,f = y.outlier(df['latitude'])\n",
    "    # start_location = df[(df['longitude']>a)&(df['longitude']<b)&(df['latitude']>d)&(df['latitude']<e)]\n",
    "    # sl = start_location.loc[:,['longitude','latitude']]\n",
    "    # print(sl.describe())\n",
    "    # print(f'Number of outlier for longitude is {c}')\n",
    "    # print(f'Number of outlier for latitude is {f}')\n",
    "\n",
    "    # fig, axs = plt.subplots(ncols=2)\n",
    "    # sns.distplot(sl['longitude'],color='b', ax=axs[0])\n",
    "    # sns.distplot(sl['latitude'], color='r', ax=axs[1])\n",
    "    # plt.show()\n",
    "\n",
    "    # m = y.get_aggregate('month')\n",
    "    # h = y.get_aggregate('hour')\n",
    "    # d = y.get_aggregate('weekday')\n",
    "    # print(m,h,d)\n",
    "\n",
    "    # d = y.map_best_month()\n",
    "    # print(d)\n",
    "#--------------------------------------------------------------\n",
    "    # Plot trip_distance distribution\n",
    "    # start_time = time.time()\n",
    "    # g,h,k = y.outlier(t['trip_distance'])\n",
    "    # d = t[(t['trip_distance']<h)&(t['trip_distance']>g)]\n",
    "    # sns.distplot(d['trip_distance'])\n",
    "    # plt.show()\n",
    "    # end_time = time.time()\n",
    "    # print('Run time', end_time-start_time)\n",
    "#-----------------------------------------------------------------------------\n",
    "    # # Create full NYC file\n",
    "    # x = trips_input()\n",
    "    # d = x.get_trips(fraction=1,optimize=True)\n",
    "    # start_time = time.time()\n",
    "    # cols = 'tpep_dropoff_datetime tpep_pickup_datetime PULocationID DOLocationID'.split( )\n",
    "    # t = d[cols]\n",
    "    # y = trips_info(t)\n",
    "    # df = y.get_position()\n",
    "    # df2 = y.get_time()\n",
    "    # df3 = y.get_duration()\n",
    "    # nyc = pd.concat((df,df2),axis=1)\n",
    "    # nyc['duration'] = df3.duration\n",
    "    # nyc = nyc.drop(cols,axis=1)\n",
    "    # # cols_to_use = nyc.columns.difference(t.columns)\n",
    "    # full_nyc = pd.concat((nyc,d),axis=1)\n",
    "    # full_nyc = full_nyc.drop(['tpep_dropoff_datetime', 'tpep_pickup_datetime'], axis=1)\n",
    "    # # tp = trips_info(time_position)\n",
    "    # # ready = tp.structure()\n",
    "    # end_time = time.time()\n",
    "    # print('Run time ',end_time-start_time)\n",
    "    # print(full_nyc.info())\n",
    "    # print(full_nyc.head())\n",
    "    # full_nyc.to_csv(r'C:/Users/kyral/Documents/MIB 2019/BI Capstone Project/trip_data/nyc.csv')\n",
    "# --------------------------------------------------------------\n",
    "    # # Test Queens\n",
    "#   \n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "    # #Build model\n",
    "    # def pre_process(d):\n",
    "    #     d.passenger_count = d.passenger_count.astype('uint8')\n",
    "    #     d.RatecodeID = d.RatecodeID.astype('uint8')\n",
    "    #     d.payment_type = d.payment_type.astype('uint8')\n",
    "    #     d.PULocationID = d.PULocationID.astype('uint16')\n",
    "    #     d.DOLocationID = d.DOLocationID.astype('uint16')\n",
    "    #     monetary = 'fare_amount tip_amount total_amount tolls_amount extra mta_tax'.split()\n",
    "    #     d[monetary] = abs(d[monetary].apply(lambda x: (x * 100).astype('int32')))\n",
    "    #     d.improvement_surcharge = d.improvement_surcharge.astype('float32')\n",
    "    #     d.congestion_surcharge = d.congestion_surcharge.astype('float32')\n",
    "    #     d.trip_distance = abs(d.trip_distance.astype('float32'))\n",
    "    #     return d\n",
    "\n",
    "    #Chunked full file\n",
    "    # start_time = time.time()\n",
    "    # data = pd.read_csv(r'C:/Users/kyral/Documents/MIB 2019/BI Capstone Project/trip_data/full.csv',chunksize=100000,sep=',')\n",
    "\n",
    "    # models = []\n",
    "    # for chunk in data:\n",
    "    #     chunk = pre_process(chunk)\n",
    "    #     model = LinearRegression()\n",
    "    #     model.fit(chunk.drop(['passenger_count','tpep_dropoff_datetime','tpep_pickup_datetime'],axis=1), chunk['passenger_count'])\n",
    "    #     models.append(model)\n",
    "    #     model.predict(chunk.drop(['passenger_count','tpep_dropoff_datetime','tpep_pickup_datetime'],axis=1))\n",
    "    # end_time = time.time()\n",
    "    # print('Process time:', end_time - start_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  PUlon  PUlat  DOlon  DOlat  PUmonth  PUhour  DOmonth  DOhour  \\\n",
      "0     1210572 -74.00  40.77 -74.00  40.75        1      21        1      21   \n",
      "1      859969 -73.93  40.75 -73.98  40.76        1       4        1       4   \n",
      "2     1147389 -73.96  40.78 -73.96  40.78        1      15        1      16   \n",
      "3     2080978 -74.00  40.75 -74.01  40.74        1      22        1      22   \n",
      "4     4197499 -73.98  40.76 -73.98  40.76        1      10        1      10   \n",
      "\n",
      "  PUweekday  ... DOLocationID  payment_type  fare_amount  extra  mta_tax  \\\n",
      "0       Tue  ...           68             1          750     50       50   \n",
      "1       Mon  ...          161             1         1000    300       50   \n",
      "2       Tue  ...          236             1         1050    100       50   \n",
      "3       Sat  ...          158             2         1350     50       50   \n",
      "4       Wed  ...          161             1         1100      0       50   \n",
      "\n",
      "   tip_amount  tolls_amount  improvement_surcharge  total_amount  \\\n",
      "0         225             0                    0.3          1356   \n",
      "1         200             0                    0.3          1580   \n",
      "2         100             0                    0.3          1580   \n",
      "3           0             0                    0.3          1730   \n",
      "4         358             0                    0.3          1788   \n",
      "\n",
      "   congestion_surcharge  \n",
      "0                   2.5  \n",
      "1                   2.5  \n",
      "2                   2.5  \n",
      "3                   2.5  \n",
      "4                   2.5  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23838931 entries, 0 to 23838930\n",
      "Data columns (total 28 columns):\n",
      "Unnamed: 0               int64\n",
      "PUlon                    float64\n",
      "PUlat                    float64\n",
      "DOlon                    float64\n",
      "DOlat                    float64\n",
      "PUmonth                  int64\n",
      "PUhour                   int64\n",
      "DOmonth                  int64\n",
      "DOhour                   int64\n",
      "PUweekday                object\n",
      "DOweekday                object\n",
      "PUweekend                int64\n",
      "DOweekend                int64\n",
      "duration                 int64\n",
      "passenger_count          int64\n",
      "trip_distance            float64\n",
      "RatecodeID               int64\n",
      "PULocationID             int64\n",
      "DOLocationID             int64\n",
      "payment_type             int64\n",
      "fare_amount              int64\n",
      "extra                    int64\n",
      "mta_tax                  int64\n",
      "tip_amount               int64\n",
      "tolls_amount             int64\n",
      "improvement_surcharge    float64\n",
      "total_amount             int64\n",
      "congestion_surcharge     float64\n",
      "dtypes: float64(7), int64(19), object(2)\n",
      "memory usage: 5.0+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:/Users/kyral/Documents/MIB 2019/BI Capstone Project/trip_data/nyc.csv',sep=',')\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queens data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = trips_input()\n",
    "df = x.get_queens()\n",
    "print(df.info())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create full NYC dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = trips_input()\n",
    "d = x.get_trips(fraction=1,optimize=True)\n",
    "cols = 'tpep_dropoff_datetime tpep_pickup_datetime PULocationID DOLocationID'.split( )\n",
    "t = d[cols]\n",
    "y = trips_info(t)\n",
    "df = y.get_position()\n",
    "df2 = y.get_time()\n",
    "df3 = y.get_duration()\n",
    "nyc = pd.concat((df,df2),axis=1)\n",
    "nyc['duration'] = df3.duration\n",
    "nyc = nyc.drop(cols,axis=1)\n",
    "full_nyc = pd.concat((nyc,d),axis=1)  \n",
    "full_nyc = full_nyc.drop(['tpep_dropoff_datetime', 'tpep_pickup_datetime'], axis=1)\n",
    "print(full_nyc.info())\n",
    "print(full_nyc.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(d):\n",
    "    # Optimize size by changing dtypes\n",
    "    d.passenger_count = d.passenger_count.astype('uint8')\n",
    "    d.RatecodeID = d.RatecodeID.astype('uint8')\n",
    "    d.payment_type = d.payment_type.astype('uint8')\n",
    "    d.PULocationID = d.PULocationID.astype('uint16')\n",
    "    d.DOLocationID = d.DOLocationID.astype('uint16')\n",
    "    monetary = 'fare_amount tip_amount total_amount tolls_amount extra mta_tax'.split()\n",
    "    d[monetary] = abs(d[monetary].apply(lambda x: (x * 100).astype('int32')))\n",
    "    d.improvement_surcharge = d.improvement_surcharge.astype('float32')\n",
    "    d.congestion_surcharge = d.congestion_surcharge.astype('float32')\n",
    "    d.trip_distance = abs(d.trip_distance.astype('float32'))\n",
    "    \n",
    "    # LOCATION CONDITIONS\n",
    "    d =d[(d['PULocationID']<=263) & (d['DOLocationID']<=263)]\n",
    "    \n",
    "    #DEALING WITH FEATURES THAT ARE ONLY MEANINGFUL WHEN IT IS >=0\n",
    "    c03=d['extra']>=0\n",
    "    c04=d['mta_tax']>=0\n",
    "    c05=d['tip_amount']>=0\n",
    "    c06=d['tolls_amount']>=0\n",
    "    c07=d['improvement_surcharge']>=0\n",
    "    c08=d['total_amount']>=0\n",
    "    c09=d['congestion_surcharge']>=0\n",
    "    d= d[ c03 & c04 & c05 & c06 & c07 & c08 & c09]\n",
    "    \n",
    "    #DEALING WITH FEATURES THAT ARE ONLY MEANINGFUL WHEN IT IS >0\n",
    "    #DURATIOIN CONDITION\n",
    "    c01=  d['duration']>0\n",
    "    # PASSENGER COUNT CONDITION \n",
    "    c02= d['passenger_count']>0\n",
    "    d= d[c01 & c02]\n",
    "    \n",
    "    # DEALING WITH FEATURES trip distance ==0  => 0.1\n",
    "    d['trip_distance']= d['trip_distance'].replace({0:0.1})\n",
    "    \n",
    "    # Speed conditions\n",
    "    sc1= (d['trip_distance']/d['duration'])<=0.009 # < 34MPH\n",
    "    sc2= (d['trip_distance']/d['duration'])>0.00097 # >3.5MPH\n",
    "    d= d[sc1 & sc2]\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
