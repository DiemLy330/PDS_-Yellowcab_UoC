{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import datetime as dt\n",
    "import re\n",
    "import os\n",
    "import geojson\n",
    "import seaborn as sns\n",
    "from shapely.geometry import shape, GeometryCollection\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "import pandas \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def map():\n",
    "    with open('D:/TOPIC_RELATED VOCABULARY IELTS/Finland/aalto/cemsschool/Other Courses/programming course for DS/project/taxi_zones.geojson') as f:\n",
    "        gj = geojson.load(f)\n",
    "    features = gj['features']\n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info(a):\n",
    "    print('it has dimensions {}, shape {}, size {}'.format(a.ndim,a.shape,a.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it has dimensions 1, shape (6339567,), size 6339567\n"
     ]
    }
   ],
   "source": [
    "def zone():\n",
    "    \n",
    "    #os.getcwd()\n",
    "    #os.chdir('C:/Users/ADMIN/AppData/Local/tmc/vscode/hy-data-analysis-with-python-2020/part03-e03_most_frequent_first/src/')\n",
    "    file = pd.read_csv('D:/TOPIC_RELATED VOCABULARY IELTS/Finland/aalto/cemsschool/Other Courses/programming course for DS/project/taxi_zones.csv',sep=',')\n",
    "    return file[file.Borough == 'Queens']\n",
    "\n",
    "# Filter Queens trips: Open trip files and return data relates to Queens borough, then merge seperate files into 1 dataframe.\n",
    "def data():\n",
    "    z = zone()\n",
    "    queens = z.LocationID.unique()\n",
    "    result = []\n",
    "    for i in range(1,10):\n",
    "        raw = pd.read_parquet(f'D:/TOPIC_RELATED VOCABULARY IELTS/Finland/aalto/cemsschool/Other Courses/programming course for DS/project//trip_data/0{i}.parquet', engine='pyarrow')\n",
    "        df = raw[raw['PULocationID'].isin(queens)]\n",
    "        df['Month'] = i\n",
    "        result.append(df)\n",
    "    for j in range(10,13):\n",
    "        raw = pd.read_parquet(f'D:/TOPIC_RELATED VOCABULARY IELTS/Finland/aalto/cemsschool/Other Courses/programming course for DS/project//trip_data/{i}.parquet', engine='pyarrow')\n",
    "        df = raw[raw['PULocationID'].isin(queens)]\n",
    "        df['Month'] = j\n",
    "        result.append(df)\n",
    "    return pd.concat(result)\n",
    "\n",
    "\n",
    "\n",
    "df = zone()\n",
    "#df.to_csv(\"C:/Users/kyral/Documents/GitHub/PDS_Yellowcab_UoC/data/output/locationID.csv\")\n",
    "#print('fdsfds')\n",
    "#d = data()\n",
    "#info(df)\n",
    "\n",
    "queens = df['LocationID'].unique()\n",
    "#print(d.head())\n",
    "raw = pd.read_parquet(f'D:/TOPIC_RELATED VOCABULARY IELTS/Finland/aalto/cemsschool/Other Courses/programming course for DS/project//trip_data/01.parquet', engine='pyarrow')\n",
    "idx = raw['PULocationID'].isin(queens)\n",
    "#info(queens)\n",
    "info(idx) #it has dimensions 1, shape (6339567,)\n",
    "res= raw[idx]\n",
    "#info(res) 414196\n",
    "# d.to_csv(\"C:/Users/kyral/Documents/GitHub/PDS_Yellowcab_UoC/data/output/trips.csv\")\n",
    "#print(res.head())\n",
    "#print(np.sum(res['tpep_pickup_datetime'].dt.weekday==0))\n",
    "#print(res['tpep_pickup_datetime'].dt.weekday.unique())\n",
    "satraw= raw['tpep_pickup_datetime'].dt.weekday==5\n",
    "satres= res['tpep_pickup_datetime'].dt.weekday==5\n",
    "sunraw= raw['tpep_pickup_datetime'].dt.weekday==6\n",
    "sunres= res['tpep_pickup_datetime'].dt.weekday==6\n",
    "#info(sat)\n",
    "#info(sun)\n",
    "d1 = dict(zip(np.arange(0,7),[0,0,0,0,0,1,1]))\n",
    "s1res = pd.Series(res.iloc[:,0].dt.weekday.map(d1))\n",
    "s1raw= pd.Series(raw.iloc[:,0].dt.weekday.map(d1))\n",
    "#print(np.sum(res['weekend']==1))\n",
    "#print(res.head())\n",
    "#print(res.iloc[:,1]-res.iloc[:,0])\n",
    "s1res =s1res.rename('weekend')\n",
    "s1raw = s1raw.rename('weekend')\n",
    "#print(s1)\n",
    "res= pd.concat((res,s1res),axis=1)\n",
    "raw= pd.concat((raw,s1raw), axis=1)\n",
    "#info(res)\n",
    "#info(res2)\n",
    "#print(res2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#info(raw)\n",
    "features= map()\n",
    "#print(features[0:10])\n",
    "#print(len(features))\n",
    "\n",
    "#print(len(features[0]))\n",
    "L = []\n",
    "for i in np.arange(2,10):\n",
    "    shape= features[i]['geometry']['coordinates'][0]\n",
    "#shape1= features[1]['geometry']['coordinates'][0]\n",
    "#co =Polygon(shape1[0]).centroid.coords\n",
    "    co =Polygon(shape).centroid.coords\n",
    "#co1 = MultiPolygon(shape1[0])\n",
    "#print(queens)\n",
    "#zip(,co)\n",
    "#print(len(shape1[0]))\n",
    "    colist = list(co)\n",
    "    \n",
    "    L.append(colist)\n",
    "#print(len(L))\n",
    "subqueens = queens[0:8]\n",
    "d1 = dict(zip(subqueens,L))\n",
    "#print(d1)\n",
    "a = pd.Series(res['PULocationID'].map(d1))\n",
    "idx = a.notnull()\n",
    "#info(idx)\n",
    "#info(a)\n",
    "#info(res)\n",
    "#print(a)\n",
    "#print(a[idx])\n",
    "#print(len(a[idx]))\n",
    "#print(type(a[idx]))\n",
    "durationres = res.iloc[:,1]-res.iloc[:,0]\n",
    "durationraw = raw.iloc[:,1]-raw.iloc[:,0]\n",
    "durationres = durationres.rename('duration')\n",
    "durationraw = durationraw.rename('duration')\n",
    "\n",
    "res = pd.concat((res,durationres),axis=1)\n",
    "raw = pd.concat((raw,durationraw),axis=1)\n",
    "#print(raw.describe())\n",
    "#print(res.describe())\n",
    "#print((duration))\n",
    "#print(res.head)\n",
    "#print(duration.mean())\n",
    "#print(duration.std())\n",
    "b = res.iloc[:,0]\n",
    "b= b.reindex(b)\n",
    "#print(b.index.dayofweek.unique())\n",
    "d2= dict(zip(np.arange(0,7),np.arange(11,18)))\n",
    "values = b.index.dayofweek.map(d2)\n",
    "#info(values)\n",
    "#pd.concat([values,b])\n",
    "#print(type(values))\n",
    "seva= values.to_series()\n",
    "#print(np.sum(b.index.duplicated()))\n",
    "seva.index= np.arange(0,414196)\n",
    "#print(seva)\n",
    "#se = pd.concat((b,seva), axis=1)\n",
    "#print((se.isnull()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it has dimensions 2, shape (331356, 15), size 4970340\n",
      "it has dimensions 1, shape (331356,), size 331356\n",
      "it has dimensions 2, shape (82840, 15), size 1242600\n",
      "0.9991340915511805\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#pd.concat((res,duration))\n",
    "#print(res[0:30])\n",
    "#res= res.set_index('tpep_pickup_datetime')\n",
    "#print(res.groupby('day'))\n",
    "#print(res.head())\n",
    "#print(res.index.floor('d'))\n",
    "#res.groupby(res[])\n",
    "#print(res.groupby(res['tpep_pickup_datetime'].dt.dayofweek).mean())\n",
    "#print(res.groupby(res['tpep_dropoff_datetime'].dt.dayofweek).mean())\n",
    "#print(res.groupby(res['tpep_pickup_datetime'].dt.month).mean())\n",
    "#print(res.groupby(res['tpep_pickup_datetime'].dt.hour).mean())\n",
    "#print(res.iloc[:,0].dt.weekday.unique())\n",
    "#print(res['weekend']==1)\n",
    "#info(res['weekend']==1)\n",
    "#print(np.sum(res['weekend']==1))\n",
    "#print(res.groupby(res['weekend']).mean())\n",
    "#print(res[-100::][::-1])\n",
    "#print(duration)\n",
    "#help(seaborn.heatmap)\n",
    "#help(res.pivot)\n",
    "#print(res['duration'].total_seconds())\n",
    "#print(300/3600)\n",
    "#print(5/60)\n",
    "timestr= '00:04:23'\n",
    "ftr = [3600,60,1]\n",
    "L1= [int(i) for i in timestr.split(':')]\n",
    "#print(L1)\n",
    "#print([a*b for a,b in zip(ftr,L1)])) 1*23s + 4'*60s + 0h*3600s\n",
    "\n",
    "ares= res['duration']/np.timedelta64(1,'s')\n",
    "#araw= raw['duration']/np.timedelta64(1,'s')\n",
    "ares.T.drop_duplicates()\n",
    "#araw.T.drop_duplicates()\n",
    "#print(ares)\n",
    "duflres=pd.Series(ares).rename('durationfloat')\n",
    "#print(ares)\n",
    "#print(res.head())\n",
    "#duflraw=pd.Series(araw).rename('durationfloat')\n",
    "res= pd.concat((res,duflres),axis=1)\n",
    "#raw= pd.concat((raw, duflraw), axis=1)\n",
    "#res.T.drop_duplicates(inplace=True)\n",
    "#print(res.describe())\n",
    "#print(raw.describe())\n",
    "idxres = res.iloc[:,-1]>=0\n",
    "#idxraw = raw.iloc[:,-1]>=0\n",
    "#rawraw= raw[idxraw]\n",
    "#print(rawraw.describe())\n",
    "#print(len(rawraw))\n",
    "#GET RID OF OUTLIERS (9.9*10^2 -3.8*10^2)*1.5=9.15*10^2|| 9.9*10^2 + 9.15*10^2\n",
    "#idxoutli= rawraw.iloc[:,-1]<=1905\n",
    "#rawraw= rawraw[idxoutli]\n",
    "#print(stats.shapiro(rawraw.iloc[0:4000:,-1]))\n",
    "#print(res.head())\n",
    "#print(5%3)\n",
    "#print(res.groupby(res['tpep_pickup_datetime'].dt.month).mean())\n",
    "#print(res.groupby(res['dufl'].dt.month.mean()))\n",
    "#duration/np.timedelta64(1,'s')\n",
    "#https://stackoverflow.com/questions/26456825/convert-timedelta64ns-column-to-seconds-in-python-pandas-dataframe/50500560\n",
    "#help(np.timedelta64)\n",
    "#info(res)\n",
    "#plt.hist(res.iloc[:,19],bins=414196)\n",
    "#info(res.iloc[:,19])\n",
    "#print(res.iloc[:,19].max())#-res.iloc[:,19].min()\n",
    "\n",
    "#print(res.iloc[:,19].min())\n",
    "#ran= res.iloc[:,19].max()-res.iloc[:,19].min()\n",
    "#ranraw = rawraw.iloc[:,-1].max()-rawraw.iloc[:,-1].min()\n",
    "#numinterval= np.sqrt(len(res))\n",
    "#numintervalraw= np.sqrt(len(rawraw))\n",
    "#print(numinterval)\n",
    "#bins= ran/numinterval\n",
    "#bins = ranraw/numintervalraw\n",
    "#print(bins)\n",
    "#print(rawraw.describe())\n",
    "#plt.hist(res.iloc[:,19],bins=np.arange(0,4000))\n",
    "#print(rawraw.describe())\n",
    "\n",
    "#2c/ q-q plot\n",
    "#kurtosis, skewness\n",
    "#plt.hist(rawraw.iloc[:,-1], bins=50) # right skewed\n",
    "#https://datatofish.com/plot-histogram-python/\n",
    "#help(plt.hist)\n",
    "#print(np.sum(res.iloc[:,19]>1000))\n",
    "# visual inspection: q-q plot/ stat: shapiro wilk test\n",
    "#3b/\n",
    "#info(res)\n",
    "#cor = res.corr()\n",
    "#plt.figure(figsize = (10,6))\n",
    "#sns.heatmap(cor,annot=True)\n",
    "#3/\n",
    "#K-fold Cross validation \n",
    "# training and testing data points\n",
    "#normalize the data features (level of measurement )\n",
    "#pca\n",
    "#3b/\n",
    "#print(np.arange(22)==6)\n",
    "#print(res.shape[1])\n",
    "#print(res.iloc[:,[i for i in np.arange(res.shape[1])]])\n",
    "#print(res.iloc[:,[i for i in np.arange(res.shape[1]) if i!=8]]) # column fare_amount is not included\n",
    "#model1= LinearRegression()\n",
    "#model1.fit(res.iloc[:,],res.iloc[:,6])\n",
    "idxdup = ~res.columns.duplicated() # return a boolean array\n",
    "#https://stackoverflow.com/questions/14984119/python-pandas-remove-duplicate-columns\n",
    "#print(len(df))\n",
    "#print(len(res.columns))\n",
    "#print(len(df))\n",
    "res =res.loc[:,idxdup]\n",
    "#info(res)\n",
    "#print(res.head())\n",
    "#print(res.iloc[:,[i for i in np.arange(res.shape[1]) if i!=8]])\n",
    "X= res.iloc[:,[i for i in np.arange(res.shape[1]) if i!=0 if i!=1 if i!=8 if i!=17  ]]\n",
    "y=res.iloc[:,8]\n",
    "Xtrain,Xtest, ytrain, ytest= train_test_split(X,y, train_size=0.8,random_state=0)\n",
    "info(Xtrain)\n",
    "info(ytrain)\n",
    "info(Xtest)\n",
    "model1.fit(Xtrain,ytrain)\n",
    "#print(model1.coef_)\n",
    "#print(model1.score(Xtest,ytest))\n",
    "#info(X)\n",
    "model2 = PolynomialFeatures()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function hist in module matplotlib.pyplot:\n",
      "\n",
      "hist(x, bins=None, range=None, density=False, weights=None, cumulative=False, bottom=None, histtype='bar', align='mid', orientation='vertical', rwidth=None, log=False, color=None, label=None, stacked=False, *, data=None, **kwargs)\n",
      "    Plot a histogram.\n",
      "    \n",
      "    Compute and draw the histogram of *x*.  The return value is a tuple\n",
      "    (*n*, *bins*, *patches*) or ([*n0*, *n1*, ...], *bins*, [*patches0*,\n",
      "    *patches1*, ...]) if the input contains multiple data.  See the\n",
      "    documentation of the *weights* parameter to draw a histogram of\n",
      "    already-binned data.\n",
      "    \n",
      "    Multiple data can be provided via *x* as a list of datasets\n",
      "    of potentially different length ([*x0*, *x1*, ...]), or as\n",
      "    a 2-D ndarray in which each column is a dataset.  Note that\n",
      "    the ndarray form is transposed relative to the list form.\n",
      "    \n",
      "    Masked arrays are not supported.\n",
      "    \n",
      "    The *bins*, *range*, *weights*, and *density* parameters behave as in\n",
      "    `numpy.histogram`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    x : (n,) array or sequence of (n,) arrays\n",
      "        Input values, this takes either a single array or a sequence of\n",
      "        arrays which are not required to be of the same length.\n",
      "    \n",
      "    bins : int or sequence or str, default: :rc:`hist.bins`\n",
      "        If *bins* is an integer, it defines the number of equal-width bins\n",
      "        in the range.\n",
      "    \n",
      "        If *bins* is a sequence, it defines the bin edges, including the\n",
      "        left edge of the first bin and the right edge of the last bin;\n",
      "        in this case, bins may be unequally spaced.  All but the last\n",
      "        (righthand-most) bin is half-open.  In other words, if *bins* is::\n",
      "    \n",
      "            [1, 2, 3, 4]\n",
      "    \n",
      "        then the first bin is ``[1, 2)`` (including 1, but excluding 2) and\n",
      "        the second ``[2, 3)``.  The last bin, however, is ``[3, 4]``, which\n",
      "        *includes* 4.\n",
      "    \n",
      "        If *bins* is a string, it is one of the binning strategies\n",
      "        supported by `numpy.histogram_bin_edges`: 'auto', 'fd', 'doane',\n",
      "        'scott', 'stone', 'rice', 'sturges', or 'sqrt'.\n",
      "    \n",
      "    range : tuple or None, default: None\n",
      "        The lower and upper range of the bins. Lower and upper outliers\n",
      "        are ignored. If not provided, *range* is ``(x.min(), x.max())``.\n",
      "        Range has no effect if *bins* is a sequence.\n",
      "    \n",
      "        If *bins* is a sequence or *range* is specified, autoscaling\n",
      "        is based on the specified bin range instead of the\n",
      "        range of x.\n",
      "    \n",
      "    density : bool, default: False\n",
      "        If ``True``, draw and return a probability density: each bin\n",
      "        will display the bin's raw count divided by the total number of\n",
      "        counts *and the bin width*\n",
      "        (``density = counts / (sum(counts) * np.diff(bins))``),\n",
      "        so that the area under the histogram integrates to 1\n",
      "        (``np.sum(density * np.diff(bins)) == 1``).\n",
      "    \n",
      "        If *stacked* is also ``True``, the sum of the histograms is\n",
      "        normalized to 1.\n",
      "    \n",
      "    weights : (n,) array-like or None, default: None\n",
      "        An array of weights, of the same shape as *x*.  Each value in\n",
      "        *x* only contributes its associated weight towards the bin count\n",
      "        (instead of 1).  If *density* is ``True``, the weights are\n",
      "        normalized, so that the integral of the density over the range\n",
      "        remains 1.\n",
      "    \n",
      "        This parameter can be used to draw a histogram of data that has\n",
      "        already been binned, e.g. using `numpy.histogram` (by treating each\n",
      "        bin as a single point with a weight equal to its count) ::\n",
      "    \n",
      "            counts, bins = np.histogram(data)\n",
      "            plt.hist(bins[:-1], bins, weights=counts)\n",
      "    \n",
      "        (or you may alternatively use `~.bar()`).\n",
      "    \n",
      "    cumulative : bool or -1, default: False\n",
      "        If ``True``, then a histogram is computed where each bin gives the\n",
      "        counts in that bin plus all bins for smaller values. The last bin\n",
      "        gives the total number of datapoints.\n",
      "    \n",
      "        If *density* is also ``True`` then the histogram is normalized such\n",
      "        that the last bin equals 1.\n",
      "    \n",
      "        If *cumulative* is a number less than 0 (e.g., -1), the direction\n",
      "        of accumulation is reversed.  In this case, if *density* is also\n",
      "        ``True``, then the histogram is normalized such that the first bin\n",
      "        equals 1.\n",
      "    \n",
      "    bottom : array-like, scalar, or None, default: None\n",
      "        Location of the bottom of each bin, ie. bins are drawn from\n",
      "        ``bottom`` to ``bottom + hist(x, bins)`` If a scalar, the bottom\n",
      "        of each bin is shifted by the same amount. If an array, each bin\n",
      "        is shifted independently and the length of bottom must match the\n",
      "        number of bins. If None, defaults to 0.\n",
      "    \n",
      "    histtype : {'bar', 'barstacked', 'step', 'stepfilled'}, default: 'bar'\n",
      "        The type of histogram to draw.\n",
      "    \n",
      "        - 'bar' is a traditional bar-type histogram.  If multiple data\n",
      "          are given the bars are arranged side by side.\n",
      "        - 'barstacked' is a bar-type histogram where multiple\n",
      "          data are stacked on top of each other.\n",
      "        - 'step' generates a lineplot that is by default unfilled.\n",
      "        - 'stepfilled' generates a lineplot that is by default filled.\n",
      "    \n",
      "    align : {'left', 'mid', 'right'}, default: 'mid'\n",
      "        The horizontal alignment of the histogram bars.\n",
      "    \n",
      "        - 'left': bars are centered on the left bin edges.\n",
      "        - 'mid': bars are centered between the bin edges.\n",
      "        - 'right': bars are centered on the right bin edges.\n",
      "    \n",
      "    orientation : {'vertical', 'horizontal'}, default: 'vertical'\n",
      "        If 'horizontal', `~.Axes.barh` will be used for bar-type histograms\n",
      "        and the *bottom* kwarg will be the left edges.\n",
      "    \n",
      "    rwidth : float or None, default: None\n",
      "        The relative width of the bars as a fraction of the bin width.  If\n",
      "        ``None``, automatically compute the width.\n",
      "    \n",
      "        Ignored if *histtype* is 'step' or 'stepfilled'.\n",
      "    \n",
      "    log : bool, default: False\n",
      "        If ``True``, the histogram axis will be set to a log scale. If\n",
      "        *log* is ``True`` and *x* is a 1D array, empty bins will be\n",
      "        filtered out and only the non-empty ``(n, bins, patches)``\n",
      "        will be returned.\n",
      "    \n",
      "    color : color or array-like of colors or None, default: None\n",
      "        Color or sequence of colors, one per dataset.  Default (``None``)\n",
      "        uses the standard line color sequence.\n",
      "    \n",
      "    label : str or None, default: None\n",
      "        String, or sequence of strings to match multiple datasets.  Bar\n",
      "        charts yield multiple patches per dataset, but only the first gets\n",
      "        the label, so that `~.Axes.legend` will work as expected.\n",
      "    \n",
      "    stacked : bool, default: False\n",
      "        If ``True``, multiple data are stacked on top of each other If\n",
      "        ``False`` multiple data are arranged side by side if histtype is\n",
      "        'bar' or on top of each other if histtype is 'step'\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    n : array or list of arrays\n",
      "        The values of the histogram bins. See *density* and *weights* for a\n",
      "        description of the possible semantics.  If input *x* is an array,\n",
      "        then this is an array of length *nbins*. If input is a sequence of\n",
      "        arrays ``[data1, data2, ...]``, then this is a list of arrays with\n",
      "        the values of the histograms for each of the arrays in the same\n",
      "        order.  The dtype of the array *n* (or of its element arrays) will\n",
      "        always be float even if no weighting or normalization is used.\n",
      "    \n",
      "    bins : array\n",
      "        The edges of the bins. Length nbins + 1 (nbins left edges and right\n",
      "        edge of last bin).  Always a single array even when multiple data\n",
      "        sets are passed in.\n",
      "    \n",
      "    patches : `.BarContainer` or list of a single `.Polygon` or list of such objects\n",
      "        Container of individual artists used to create the histogram\n",
      "        or list of such containers if there are multiple input datasets.\n",
      "    \n",
      "    Other Parameters\n",
      "    ----------------\n",
      "    **kwargs\n",
      "        `~matplotlib.patches.Patch` properties\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    hist2d : 2D histograms\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    For large numbers of bins (>1000), 'step' and 'stepfilled' can be\n",
      "    significantly faster than 'bar' and 'barstacked'.\n",
      "    \n",
      "    .. note::\n",
      "        In addition to the above described arguments, this function can take\n",
      "        a *data* keyword argument. If such a *data* argument is given,\n",
      "        the following arguments can also be string ``s``, which is\n",
      "        interpreted as ``data[s]`` (unless this raises an exception):\n",
      "        *x*, *weights*.\n",
      "    \n",
      "        Objects passed as **data** must support item access (``data[s]``) and\n",
      "        membership test (``s in data``).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(pd.DataFrame([[1,2,3,4],list('abcd')], columns=list(\"ABCD\")))\n",
    "\n",
    "#('C:/Users/ADMIN/AppData/Local/tmc/vscode/hy-data-analysis-with-python-2020/part03-e03_most_frequent_first/src/most_frequent_first.py')\n",
    "help(plt.hist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
